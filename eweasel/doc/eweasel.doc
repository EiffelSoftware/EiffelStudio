
EiffelWeasel: An Automated Regression Testing Tool for ISE Eiffel
=================================================================

The EiffelWeasel test suite execution program executes an Eiffel
compilation and execution test suite.  It only supports the ISE Eiffel
5.x environment.

Usage:

   eweasel [-help] [-keep {all | passed | failed}] [-clean] [-filter FILTER] 
	[-define name value ...] 
	-init init_control_file -catalog test_catalog -output test_suite_dir

The -help options displays command line help and then exits.

The -keep option specifies that the directory tree generated from
executing the test is to be kept for certain tests indicated by the
next parameter:

	-keep all 	Keep generated directory for all tests, whether
			they pass or fail

	-keep passed 	Keep generated directory for all tests that pass

	-keep failed 	Keep generated directory for all tests that failed

In the absence of this option, eweasel deletes the entire
directory tree generated for each, whether it passes or fails.

The -clean option specifies that the EIFGENs/test directory that results from
running the test should be deleted, to save disk space.  Note that
this option has no effect unless the -keep option is also specified.

The -filter option allows selection of the tests to be executed.  If
this is not present, all tests in the catalog are executed, in the
order in which they appear in the catalog.  If the -filter option is
present, the next argument is a "filter" and only the tests selected
by the filter are executed.  The filter may be one of the following:

	'test <test-name>'
		
		Select for execution only the tests with the name
		<test-name>.  Since tests should have unique names,
		there is normally only one such test.
	
	'kw <test-keyword>'

		Select for execution only the tests whose catalog
		entry includes the keyword <test-keyword>.

The -define option allows you to define substitution variables on the
command line.  You will normally want to define the following
variables on the command line:

	INCLUDE		The full path name of the standard include directory
			(usually $EWEASEL/control, where $EWEASEL is the
			path name of the eweasel installation directory).
	
The -init option lets you specify the name of the initial test suite
control file, which is read and executed before the test catalog is
processed and before any tests are executed.  This control file may
only contain some of the instructions that a test control file
contains:
	
	define
	define_directory
	define_file
	undefine
	include
	if

These instructions have the same syntax and semantics as they do in a
test control file.  The test suite control file is used to define
names particular to a specific user, site or operating system.

The -catalog option lets you specify the name of of a test catalog,
which describes all the tests which are members of this test suite.
This option can appear more than once to specify multiple test
catalogs, which are effectively merged in the order given.  The test
catalog serves only to specify which tests belong to the test suite.
It does not prescribe which of these tests should be selected for
execution; this is accomplished via the -filter option.

The -output option lets you specify the name of the test suite directory.
Each test is performed in its own "test directory", which is always a
subdirectory of the test suite directory.  The subdirectory used as
the test directory for a particular test is the one which has the same
name as the last component of the pathname for the test's source
directory.

For portability, directory names in both test catalogs and test
control files should always be specified via substitution variables.
Also, file names should be kept short and should only use alphanumeric
characters.


Test catalog file format
========================

Each line specifies either zero or one tests.  Lines which contain
only white space are ignored.  Lines whose first non-white characters
are "--" are comments and are also ignored.  All other lines either
change the current source path name or specify a single test.
Commands and arguments are separated by white space.  Commands and
arguments are not case sensitive, except for arguments which represent
directory names, file names or substitution variable names or values.

The following are the possible test catalog "instructions".


if NAME <catalog-instruction>
if not NAME <catalog-instruction>

	Specifies that <catalog-instruction> is only to be processed
	if NAME has a value (or does not have a value, for "not").

source_path <directory-name>

	Specifies that <directory-name> is the full path name of the
	directory in which the source directories for subsequent tests
	reside.  Remains effective until another `source_path' occurs.

test <test-name> <source-directory-last-component> <ctrl-file> [<keyword> ...]

	Defines a test, giving it the name <test-name> and specifying
	the last component of the source directory path name.  This
	test name is not required to match the test name specified in
	<ctrl-file>.  The test control file is named <ctrl-file> and
	resides in the source directory.  

	Optional keywords may be included for classification purposes,
	so that all tests which have a particular keyword (or
	combination of keywords) can be executed.  The following keywords
	have special meaning and are reserved:

		manual	Specifies that for some reason this test must
			be performed manually.  Eweasel never executes
			these tests.  If they are selected for
			execution, they are displayed similarly to
			other tests but always get a status of
			"manual" rather than "passed" or "failed".
		
		skip	Specifies that this test should be skipped.
			Useful for temporarily marking tests as not
			executable without commenting them out.
			Eweasel never executes these tests.  If they
			are selected for execution, they are displayed
			similarly to other tests but always get a
			status of "skipped".
			

	The source directory contains all files needed to perform the
	test. These may include:
		
		- A test control file, which specifies how to perform
		  a particular test.
		
		- Files containing class texts, which are to be
		  copied into some sub-directory of the test directory,
		  with or without variable substitution.
		
		- Ace files to be copied into the test directory.
		
		- Program input files, which are input to an Eiffel
		  test program when it is executed.
		
		- Program output files, which contain the output
		  expected from executing an Eiffel test program.


Example of test catalog file
============================

Here is an example of (part of) an actual test catalog:

-- This is a test catalog.

source_path	$BUGS

-- Syntax tests

test	generic-zero-parms		syntax001 tcf syntax
test	no-index-tag			syntax002 tcf syntax
test	semicolons-not-optional		syntax003 tcf syntax

-- Validity tests

test	bad-class-end-comment		valid001 tcf validity
test	bad-infix-feature		valid002 tcf validity
test	class-not-in-universe		valid003 tcf validity

-- Incrementality tests

test	vlec-sneak			incr001  tcf incrementality validity
test	chg-inspect-const-type		incr002  tcf incrementality validity
test	vscn-sneak			incr003  tcf incrementality validity



Test specification
==================

Each test is specified by a test control file.  This control file
specifies all the information needed to carry out the test in an
automated fashion, with no human intervention required.  Note that a
test may in fact include many tests (for example, a number of
execution correctness tests).

A test control file is comprised of a sequence of instructions.  Each
instruction tells the automatic testing program which is performing
the test to take some action.  The syntax and semantics of the
instructions in a test control file are explained below.

The automatic tester processes the instructions in the test control
file sequentially.  The test only passes if the tester processes all
instructions in the file without encountering any failures.  If a
failure is encountered, the tester skips to the last instruction
(which is always a test_end instruction, since the automatic tester
adds a `test_end' instruction if the last instruction is not
`test_end').


Test Control File Instructions
==============================

Each line specifies either zero or one test instructions.  Lines which
contain only white space are ignored.  Lines whose first non-white
characters are "--" are comments and are also ignored.  All other
lines contain exactly one test instruction.  Test instruction commands
and arguments are separated by white space.  Commands and arguments
are not case sensitive, except for arguments which represent directory
names, file names or substitution variable names or values.

include <directory-name> <file-name>

	Process the lines of the file named <file-name> in directory
	<directory-name> as though they were inserted into the test
	control file at the point where the `include' appears.  An
	`include' instruction may appear in an include file, with
	depth of nesting limited only by the number of files which can
	be open simultaneously.  Recursive includes are not currently
	detected and will cause eweasel to terminate with a "too many
	open files" error.
	
if <name> <controlled_instruction>
if not <name> <controlled_instruction>

	If the substitution variable <name> has a value (or does not
	have a value, for an "if not" instruction), execute
	<controlled_instruction>.  Otherwise, skip controlled
	instruction and do not even attempt to parse it or determine
	whether it is a known instruction.  The controlled instruction
	of an `if' instruction may also be an `if instruction', with
	depth of nesting limited only by available memory.
	
test_name <name>

	The name by which this test is to be known.  May be used by
	the automatic tester to display the name of the test it is
	working on.  <name> may include white space characters, but
	leading and trailing white space is stripped from it.  The
	case of the name (uppercase/lowercase) is retained with no
	change.

test_description <description>

	A description of the test.  Includes all characters starting
	with the first non-white space character after `test_description'
	and continuing to end of line (with trailing white space
	characters stripped).  Case is not changed.

system <system-name>

	Set the name of the system, to be used to execute it.  Must
	match the system name in the Ace file or unexpected results
	will occur.  Defaults to `test' before it has been set in the
	current test control file.  Case is not changed since the
	system name is really a file name.
	
ace <file-name>

	Set the name of the last component of the Ace file pathname,
	to be used when the Eiffel compiler is run, to <file-name>.
	Defaults to `Ace' before it has been set in the current test
	control file.
	
define <name> <value>

	Define the substitution variable <name> to have the value
	<value>.  If <value> contains white space characters, it must
	be enclosed in double quotes.  Substitution of variable values
	for names is triggered by the '$' character, when substitution
	is being done.  For example, $ABC will be replaced by the last
	value defined for variable ABC.  Case is significant and by
	convention substitution variables are normally given names
	which are all uppercase.  The name starts with the first
	character after the '$' and ends with the first non-identifier
	character (alphanumeric or underline) or end of line.
	Parentheses may be used to set a substitution variable off
	from the surrouding text (e.g., the substitution variable name
	in "$(ABC)D" is ABC, not ABCD).  If the named variable has not
	been defined, it is left as is during substitution (in the
	example above it would remain $(ABC)).  To get a $ character,
	use $$.  Substitution is always done when reading the lines of
	a test suite control file, test control file or test catalog.
	Substitution is done on the lines of a copied file when
	`copy_sub' is used, but not when `copy_raw' is used.
	
	The following pre-defined substitution variables are available
	and may be used in any test control file:

	$SOURCE	
		
		Name of the source directory for this test, which
		contains all files needed to perform the test.
		
	$TEST
		
		Name of the test directory for this test (where the
		test will be performed). The test directory is created
		if it does not exist.  If it does exist, it should be
		empty since no files are deleted automatically before
		the test is started.
	
		Normally, a number of files and directories are
		created in the test directory (or copied into it)
		during the course of running the test.  These may include:
		
		- The Ace file which is input to the Eiffel compiler
		
		- The EIFGENs/test directory created and used by the 
		  Eiffel compiler
		
		- A "clusters" directory with the clusters which contain 
		  class texts (or with the class texts themselves if only
		  one cluster is needed)
		
		- An "output" directory with Eiffel compilation, C
		  compilation and execution outputs

	$CLUSTER
		
		Name of the directory where the user-created clusters
		for the test reside.  If only one such cluster is
		required for a test, class texts can be copied directly into
		this directory.  If more than one cluster is needed,
		each cluster should be specified as a subdirectory of
		$CLUSTER (via `define_directory') and then the
		appropriate classes can be copied into each
		subdirectory.
	
	$OUTPUT
		
		Name of the directory where any output generated
		during the test is placed.  This includes output from
		any Eiffel and C compilations and also output from
		system executions.
	
	$EXEC_WORK
		
		Name of the directory where the executable system
		(created by Eiffel and/or C compilations) for
		workbench mode applications resides.
	
	$EXEC_FINAL
		
		Name of the directory where the executable system
		(created by Eiffel and/or C compilations) for
		final mode applications resides.
	
		
	The following substitution variables should be defined in a
	site-specific or user-specific include file.  They are
	intended for use in Ace files, so that these files may
	be used without modification at different sites or on different
	operating systems.  They are all full path names of directories
	which contain the class texts of particular ISE-supplied clusters:

		$KERNEL		Kernel     cluster directory
		$SUPPORT	Support    cluster directory
		$ACCESS		Access     cluster directory
		$CURSORS	Cursors    cluster directory
		$DISPENSER	Dispenser  cluster directory
		$ITERATION	Iteration  cluster directory
		$LIST		List 	   cluster directory
		$OBSOLETE	Obsolete   cluster directory
		$SET		Set 	   cluster directory
		$SORT		Sort 	   cluster directory
		$STORAGE	Storage    cluster directory
		$TABLE		Table 	   cluster directory
		$TRAVERSING	Traversing cluster directory
		$TREE		Tree 	   cluster directory
	
	The following substitution variables should be defined in a
	site-specific or user-specific include file.  They are
	intended for use in the `precompiled' free option in an
	Ace file:

		$PRECOMPILED_BASE		Eiffelbase precompiled cluster
		$PRECOMPILED_BASE_VISION	Eiffelbase and Eiffelvision
		$PRECOMPILED_BASE_STORE		Eiffelbase and Eiffelstore
		$PRECOMPILED_BASE_STORE_VISION
				Eiffelbase, Eiffelvision and Eiffelstore
	
	The following substitution variables must be defined in a
	site-specific or user-specific include file.  They are
	used to determine which command to execute to accomplish tasks
	such as freezing and system execution:

		$EWEASEL_FREEZE		Full path name of command to execute
					to freeze a system
		$EWEASEL_EXECUTE	Full path name of command to execute
					to execute a system
	
undefine <name>

	Remove any previous definition of substitution variable <name>.
	No error if <name> has not been defined.

define_directory <name> <path> <subdir1> <subdir2> ...

	Similar to `define', except that <name> is defined to have the
	value which is the name of the directory specified by <path>
	and the subdirectories (which are components of the path name
	to be added onto <path> in an OS-dependent fashion).  This
	allows directory name construction to be (more or less)
	OS-independent.

define_file <name> <path> [<subdir1> <subdir2> ...] <filename>

	Similar to `define', except that <name> is defined to have the
	value which is the name of the file specified by <path>, the
	<subdirN> subdirectory names and <filename>.  This allows
	construction of full file path names to be (more or less)
	OS-independent.

setenv <name> <value>

	Set environment variable <name> with <value>.

copy_bin <source-file> <dest-directory> <dest-file>

	Copy the binary file named <source-file> from the source directory
	$SOURCE to the <dest-directory> under the name <dest-file>.
	The destination directory is created if it does not exist.

copy_raw <source-file> <dest-directory> <dest-file>

	Copy the file named <source-file> from the source directory
	$SOURCE to the <dest-directory> under the name <dest-file>.
	The destination directory is created if it does not exist.  No
	substitution is done on the lines of <source-file>.

copy_sub <source-file> <dest-directory> <dest-file>

	Similar to `copy_raw' except that occurrences of a
	substitution variable, such as $NAME, are replaced by the
	value given to NAME in the last define, define_file or
	define_directory instruction which set it (or are left as
	$NAME if NAME has not been defined).

delete <dest-directory> <dest-file>

	Delete the file named <dest-file> from the directory
	<dest-directory>.  The destination directory should not
	normally be the source directory $SOURCE.

cpu_limit <limit>

	Set the limit for Eiffel compilations to <limit> CPU seconds.
	If the time limit expires before compilation finishes, the
	compiler is presumed to be in an infinite loop and compilation
	is aborted.  This will usually cause the test to fail.

compile_melted [<output-file-name>]
compile_frozen [<output-file-name>]
compile_final [<output-file-name>]
compile_final_keep [<output-file-name>]

	Run the Eiffel compiler in the test directory $TEST with the
	Ace file specified by the last `ace' instruction.  Since the
	Ace file is always assumed to be in the test directory, it
	must have previously been copied into this directory.
	Compile_melted does not request freezing of the system,
	compile_frozen requests freezing of the system, compile_final
	requests finalizing of the system with assertions discarded,
	and compile_final_keep requests finalizing of the system with
	assertions kept.  The optional <output-file-name> specifies
	the name of the file in the output directory $OUTPUT into
	which output from this compilation will be written, so that it
	can potentially be compared with a known correct output file.
	If <output-file-name> is omitted, compilation results are
	written to a file with an unadvertised but obvious name (which
	could possibly change) in the output directory.

cleanup_compile

	Clean up a previous Eiffel compilation by deleting the entire
	EIFGENs/test directory tree.  The next Eiffel compilation will
	start with a clean slate.  If there is a suspended Eiffel
	compilation awaiting resumption, the `abort_compile'
	instruction must be used instead of this one.

abort_compile

	Abort a suspended Eiffel compilation so that another
	compilation can be started from scratch.  There can be at most
	one Eiffel compilation in progress at a time.  This
	instruction does a `cleanup' after aborting the compilation,
	which deletes the entire EIFGENs/test directory tree.

exit_compile

	Abort a suspended Eiffel compilation so that another
	compilation can be started from scratch.  There can be at most
	one Eiffel compilation in progress at a time.  This
	instruction is identical to `abort_compile' except that
	it does not delete the EIFGENs/test directory tree.

resume_compile

	Resume an Eiffel compilation which was suspended due to
	detection of a syntax or validity error.

compile_result <result>

	Check that the compilation result from the last
	compile_melted, compile_frozen, compile_final or
	resume_compile instruction matches <result>.  If it does not,
	then the test has failed.  If the result matches <result>,
	continue processing with the next test instruction.  To
	specify no class for <class> below, use NONE (which matches
	only if the compiler does not report the error in a particular
	class).  <result> can be:

		syntax_error  { <class> <line-number> ";" ... }+
			
			Matches if compiler reported a syntax error on each
			of the indicated classes at the given line numbers,
			in the order indicated.
			If <line-number> is omitted, then matches if
			compiler reported a syntax error on class
			<class>, regardless of position.  To specify
			no class (which means "syntax error on the Ace
			file"), use NONE.

		validity_error { <class> <validity-code-list> ";" ...}+
			
			Matches if compiler reported the indicated
			validity errors in the named classes in the
			order listed.  This validity code list is a
			white space separated list of validity codes
			from "Eiffel: The Language".

		validity_warning { <class> <validity-code-list> ";" ...}+
			
			Matches if compiler reported the indicated
			validity errors in the named classes in the
			order listed.  This validity code list is a
			white space separated list of validity codes
			from "Eiffel: The Language".  This is
			identical to validity_error, except that 
			the compilation is expected to complete
			for validity_warning whereas it is expected
			to be paused for validity_error.

		ok

			Matches if compiler did not report any syntax
			or validity errors and no system failure or
			run-time panic occurred and the system was
			successfully recompiled.

c_compile_work  [<output-file-name>]

	Compile the C files generated by a `compile_melted' or
	`compile_frozen' instruction.  Note that `compile_melted' can
	result in freezing if there are external routines.  The
	optional <output-file-name> specifies the name of the file in
	the output directory $OUTPUT into which output from this
	compilation will be written, so that it can potentially be
	compared with a known correct output file.  If
	<output-file-name> is omitted, compilation results are written
	to a file with an unadvertised but obvious name (which could
	possibly change) in the output directory.

c_compile_final [<output-file-name>]

	Just like `c_compile_work', except that it compiles the C
	files generated by a `compile_final' instruction.

c_compile_result <result>

	Check that the result from the last c_compile_work or
	c_compile_final instruction matches <result>.  If it does not,
	then the test has failed and the rest of the test instructions
	are skipped.  If the result matches <result>, continue
	processing with the next test instruction.  <result> can be:

		ok

			Matches if compiler successfully compiled all
			C files and linked an executable.

execute_work <input-file> <output-file> [<arg1> <arg2> ...]

	Execute the workbench version of the system named by the last
	`system' instruction (or `test' if no previous system
	instruction).  The system will get its input from <input-file>
	in the source directory $SOURCE and will place its output in
	<output-file> in the output directory $OUTPUT.  If present,
	the optional <argN> will be passed to the system as command
	line arguments.  To specify no input file or no output file,
	use the name NONE.

execute_final <input-file> <output-file> [<arg1> <arg2> ...]

	Similar to `execute_work', except that the final version of
	the system is executed.

execute_result <result>

	Check that the result from the last execute_work or
	execute_final instruction matches <result>.  If it does not,
	then the test has failed and the rest of the test instructions
	are skipped.  If the result matches <result>, continue
	processing with the next test instruction.  <result> can be:

		ok

			Matches if no exception trace or run-time
			panic occurred and there were no error
			messages of any kind.

		failed

			Matches if system did not complete normally
			(did not exit with 0 status) and output includes
			a "system execution failed" string

		failed_silently

			Matches if system did not complete normally
			(did not exit with 0 status) but output does not 
			include a "system execution failed" string

		completed_but_failed

			Matches if system completed normally
			(exited with 0 status) but output includes
			a "system execution failed" string


append_output <output-file>

	Append the file <output-file> in the output directory $OUTPUT
	onto the output of the automatic tester, indented a little
	bit.  Presumably, this means that this output file contains a
	number of individual tests and we want to see the individual
	results as well as the overall (group) result.
	
compare <output-file> <correct-output-file>

	Compare the file <output-file> in the output directory $OUTPUT
	with the file <correct-output-file> in the source directory
	$SOURCE.  If they are not identical, then the test has failed
	and the rest of the test instructions are skipped.  If they
	are identical, continue processing with the next test
	instruction.

manual_check

	Inform the automatic tester that the results cannot be checked
	automatically and must be checked manually.  This instruction
	always fails with an explanation that says the results must be
	checked manually.  This failure causes the directory tree for
	this test to be kept rather than deleted, regardless of
	whether the -keep option is specified.

test_end

	If this instruction is processed, then the test is over and
	the test has passed.
	

Examples of test control files
==============================


-- This is a test control file (syntax test)

test_name 		generic-zero-parms
test_description 	Type with zero actual generic parameters
copy_sub 		Ace $TEST Ace
copy_raw 		test1.e $CLUSTER test1.e
copy_raw 		generic.e $CLUSTER generic.e
compile_melted
compile_result 		ok
test_end

----------------------------------------------------------------------


-- This is a test control file (validity test)

	test_name 		invalid-local-rescue
test_description 	Violate Routine rule (validity constraint VRRR)
copy_sub 		Ace $TEST Ace
copy_raw 		test.e $CLUSTER test.e
compile_melted
compile_result 		validity_error TEST VRRR
test_end

----------------------------------------------------------------------

-- This is a test control file (incrementality test)

test_name 	generic-root-vcfg
test_description Add 2nd formal generic parameter of the same name to root class

copy_sub 	Ace $TEST Ace
copy_raw 	test.e $CLUSTER test.e
compile_melted
compile_result 	validity_error TEST VSRC

copy_raw 	test_rev1.e $CLUSTER test.e
resume_compile
compile_result 	validity_error TEST VCFG

test_end

----------------------------------------------------------------------

-- This is a test control file (execution test)

test_name 	plus-before-free-unary
test_description An expression with the standard binary operator infix "+" and a unary free operator

copy_sub 	Ace $TEST Ace
copy_raw 	test.e $CLUSTER test.e
compile_melted
compile_result 	ok

execute_work 	NONE exec_output1
execute_result 	ok
compare		exec_output1 output1

test_end

----------------------------------------------------------------------

-- Typical Ace file, with substitution variables

system test

root
	test (root_cluster): "make"

default

	precompiled ("$PRECOMPILED_BASE");
	assertion(all)

cluster

	root_cluster:		"$CLUSTER";
	kernel:			"$KERNEL";
	support:		"$SUPPORT";
	access:			"$ACCESS";
	cursors:		"$CURSORS";
	dispenser:		"$DISPENSER";
	iteration:		"$ITERATION";
	list:			"$LIST";
	obsolete:		"$OBSOLETE";
	set:			"$SET";
	sort:			"$SORT";
	storage:		"$STORAGE";
	table:			"$TABLE";
	traversing:		"$TRAVERSING";
	tree:			"$TREE";
end
